import os
from typing import TypedDict, List
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv

# è‡ªåŠ¨ä»é¡¹ç›®æ ¹ç›®å½•çš„ .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class AgentState(TypedDict):
    industry: str
    keywords: str
    candidates: List[dict]
    retry_count: int
    error_msg: str

# åˆå§‹åŒ– Qwen (ModelScope å…è´¹ç‰ˆ)
llm = ChatOpenAI(
    model_name="Qwen/Qwen3-32B",
    openai_api_base="https://api-inference.modelscope.cn/v1",
    openai_api_key=os.environ.get("OPENAI_API_KEY"),
    streaming=True,
    extra_body={
      "enable_thinking": True
    },
)

def generator_node(state: AgentState):
    prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å•†æ ‡å‘½åä¸“å®¶ã€‚
    
    è¯·ä¸ºä»¥ä¸‹è¡Œä¸šå’Œå…³é”®è¯ç”Ÿæˆ3ä¸ªåˆ›æ„å•†æ ‡åç§°ï¼š
    è¡Œä¸šï¼š{state['industry']}
    æ ¸å¿ƒå…³é”®è¯ï¼š{state['keywords']}
    
    èµ·åè¦æ±‚ï¼š
    1. å¿…é¡»åŒ…å«å…³é”®è¯ä¸­çš„æ ¸å¿ƒå«ä¹‰ã€‚
    2. é¿å…ä½¿ç”¨ç”Ÿåƒ»å­—å’Œä¸å‰åˆ©çš„è¯è¯­ã€‚
    3. è¾“å‡ºæ ¼å¼ï¼šè¿”å›ä¸€ä¸ªJSONåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« nameï¼ˆåç§°ï¼‰å’Œ reasonï¼ˆç®€çŸ­ç†ç”±ï¼‰ã€‚
    """
    
    print("\nğŸ¤– [æ¨¡å‹æ­£åœ¨æ€è€ƒ...]")
    full_content = ""
    
    # ä½¿ç”¨æµå¼è¾“å‡ºæ¥æ‰“å°æ€è€ƒè¿‡ç¨‹
    for chunk in llm.stream(prompt):
        # å¸¸è§çš„å¸¦æœ‰æ€ç»´é“¾çš„æ¨¡å‹ï¼ˆå¦‚ DeepSeek-R1 / QwQ ç­‰ï¼‰ä¼šå°†æ€è€ƒè¿‡ç¨‹å­˜åœ¨ reasoning_content ä¸­
        reasoning = chunk.additional_kwargs.get("reasoning_content", "")
        if reasoning:
            print(reasoning, end="", flush=True)
            
        # è·å–æœ€ç»ˆå›å¤çš„æ–‡æœ¬ï¼ˆå¦‚æœæ€è€ƒè¿‡ç¨‹æ˜¯å¸¦ <think> æ ‡ç­¾æ··æ‚åœ¨ content ä¸­ä¹Ÿä¼šè¢«æ‹¼æ¥åˆ°è¿™é‡Œï¼‰
        if chunk.content:
            full_content += chunk.content
            # æ‰“å°æ¨¡å‹è¾“å‡ºçš„å…¨éƒ¨å†…å®¹ï¼ˆå› ä¸ºæœ‰äº›æ¨¡å‹çš„æ€è€ƒè¿‡ç¨‹ç›´æ¥æ··åœ¨ content ä¸­ï¼‰
            print(chunk.content, end="", flush=True)
            
    print("\nâœ¨ [æ€è€ƒç»“æŸ]\n")
    
    # ç®€å•çš„è§£æé€»è¾‘ï¼ˆå®é™…åº”ç”¨ä¸­å»ºè®®ä½¿ç”¨ PydanticOutputParserï¼‰
    try:
        # å°è¯•ç›´æ¥è§£æJSON
        import json
        content = full_content.strip()
        
        # ç§»é™¤Markdownä»£ç å—æ ‡è®°ï¼ˆå¦‚æœæœ‰ï¼‰
        if content.startswith("```"):
            lines = content.split("\n")
            if len(lines) > 2:
                content = "\n".join(lines[1:-1])
        
        candidates = json.loads(content)
    except:
        # é™çº§å¤„ç†ï¼šç®€å•åˆ†å‰²
        candidates = []
        for line in full_content.split("\n"):
            if line.strip():
                candidates.append({"name": line.strip(), "reason": ""})
    
    return {"candidates": candidates, "retry_count": state.get('retry_count', 0) + 1}

def checker_node(state: AgentState):
    """åˆè§„æ£€æŸ¥èŠ‚ç‚¹ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    # å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨å•†æ ‡æŸ¥è¯¢API
    # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿæ£€æŸ¥å…³é”®è¯æ˜¯å¦åŒ…å«â€œé˜¿é‡Œâ€
    
    failed_names = []
    for cand in state['candidates']:
        if "é˜¿é‡Œ" in cand['name']:
            failed_names.append(cand['name'])
            cand['status'] = "fail"
        else:
            cand['status'] = "pass"
    
    if failed_names:
        return {
            "error_msg": f"ä»¥ä¸‹åç§°åŒ…å«æ•æ„Ÿè¯æˆ–å·²è¢«æ³¨å†Œï¼š{', '.join(failed_names)}",
            "candidates": state['candidates']
        }
    else:
        return {"error_msg": "", "candidates": state['candidates']}

# --- æ„å»ºå›¾é€»è¾‘ ---
workflow = StateGraph(AgentState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("generator", generator_node)
workflow.add_node("checker", checker_node)

# è®¾ç½®å…¥å£ç‚¹
workflow.set_entry_point("generator")
# è®¾ç½®è¾¹
workflow.add_edge("generator", "checker")

# æ¡ä»¶è¾¹ï¼šæ£€æŸ¥æ˜¯å¦æœ‰é€šè¿‡çš„åç§°
def should_continue(state: AgentState):
    """åˆ¤æ–­æ˜¯å¦ç»§ç»­å¾ªç¯"""
    # å¦‚æœæœ‰é€šè¿‡çš„åç§°ï¼Œæˆ–è€…å°è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™ï¼Œåˆ™åœæ­¢
    if any(c['status'] == "pass" for c in state['candidates']) or state.get('retry_count', 0) >= 3:
        return END
    else:
        return "generator"

workflow.add_conditional_edges(
    "checker",
    should_continue,
    ["generator", END]
)

# ç¼–è¯‘å›¾
graph = workflow.compile()


